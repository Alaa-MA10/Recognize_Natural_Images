{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_classification_CNN_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auajBkved_jr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg0vY76Peez_"
      },
      "source": [
        "from google.colab import drive\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRV3rNEbelC1"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0V7BWbjb5oD"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAqB-jm8buz3",
        "outputId": "387aa990-b23d-49df-82ac-6c7b8055a45e"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6N80Sw_hRFe"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFfxJrimej4S"
      },
      "source": [
        "IMG_SIZE = 90\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Neural_Project/'\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "date_time = datetime.now().strftime(\"(%Y/%m/%d, %H:%M)\")\n",
        "\n",
        "MODEL_NAME =\"64x13-CNN-(Batch & dropout)\"\n",
        "EPOCHS_NUM = 50\n",
        "log_dir = f\"logs/{MODEL_NAME}({EPOCHS_NUM})-{date_time}\"\n",
        "\n",
        "DATA_PATH = os.path.join(\"Data (npy)\")\n",
        "train_image_data = os.path.join(DATA_PATH, f'train_image - ({IMG_SIZE}-RGB).npy')\n",
        "test_image_data = os.path.join(DATA_PATH, f'test_image - ({IMG_SIZE}-RGB).npy')\n",
        "\n",
        "MODEL_FOLDER = 'CNN'\n",
        "MODEL_PATH = os.path.join('Models', f'{MODEL_FOLDER}')#,f'{MODEL_NAME}_{date_time}_({EPOCHS_NUM}_epoch).model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kKPw1OQgI_8"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iIqf_dyetk7"
      },
      "source": [
        "## Create Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gaS5ALSesv0"
      },
      "source": [
        "def create_train_data():\n",
        "  train_image = []\n",
        "\n",
        "  for c in Classes['Image']:\n",
        "    path = os.path.join('Scenes_training_set',c)   # path to building,forest,... folders , c = building,forest,..\n",
        "    class_label = list(Classes['Image']).index(c)     # class_label = 0, 1, 2, 3, 4\n",
        "\n",
        "    for img in tqdm(os.listdir(path)):\n",
        "      img_data = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
        "      img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)                  # Make it RGB \n",
        "      #img_data = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)  # Read Image and convert it to GRAY\n",
        "      img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))   # resize image\n",
        "\n",
        "      train_image.append([np.array(img_data),class_label])\n",
        "\n",
        "  shuffle(train_image)\n",
        "  np.save(train_image_data, train_image)\n",
        "\n",
        "  return train_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFGtafIgez--"
      },
      "source": [
        "## Create Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8FYzopzeww6"
      },
      "source": [
        "def create_test_data():\n",
        "  test_image = []\n",
        "  path = os.path.join('Scenes_testing_set')   # path to testing folder\n",
        "\n",
        "  for img in tqdm(os.listdir(path)):\n",
        "    img_data = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
        "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)                  # Make it RGB \n",
        "    img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))   # resize image\n",
        "    \n",
        "    test_image.append([np.array(img_data), img])\n",
        "\n",
        "  np.save(test_image_data, test_image)\n",
        "\n",
        "  return test_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpAntxsYgdBg"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY0LpDGeRyu"
      },
      "source": [
        "## 64x13-CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOoyGaH0eN1j"
      },
      "source": [
        "def create_cnn_Model(X, num_classes):\n",
        "  model = Sequential()\n",
        "\n",
        "  #Conv 1\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), input_shape=X.shape[1:], padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #Conv 2\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 1\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  #Conv 3\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #Conv 4\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 2\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  #Conv 5\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #Conv 6\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 3\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  #Conv 7\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  #Conv 8\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 4\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Conv 9\n",
        "  model.add(Conv2D(512, kernel_size=(3,3),  padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #Conv 10\n",
        "  model.add(Conv2D(512, kernel_size=(3,3),  padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 5\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Conv 11\n",
        "  model.add(Conv2D(256, kernel_size=(3,3),  padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #Conv 12\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 6\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Conv 13\n",
        "  model.add(Conv2D(512, kernel_size=(3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #POOL 7\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Flatten())                      # 'flatten' layer that turns the inputs into a vector\n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  model.add(Dropout(0.5))                   #drops 50% of the existing connections\n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  \n",
        "  # A 'dense' layer that takes that vector and generates probabilities for 6 target labels, using a Softmax \n",
        "  model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntliznYVO4iR"
      },
      "source": [
        "### Train CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEKpPTg2O6VJ"
      },
      "source": [
        "def train_CNN_model(X_train,Y_train, X_val, Y_val, model_path):\n",
        "  tensorboard = TensorBoard(log_dir, histogram_freq=1)\n",
        "\n",
        "  checkpoint_filepath = os.path.join(model_path,'64x13-CNN-(Batch & dropout)_epoch:{epoch:02d}_acc:{val_accuracy:.4f}.h5')\n",
        "  checkpoint = ModelCheckpoint(checkpoint_filepath, monitor= 'val_accuracy', mode= 'max', save_best_only= True)\n",
        "\n",
        "  CNN_model = create_cnn_Model(X, num_classes= len(Y_train[0]))\n",
        "  CNN_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  CNN_model.fit(X_train, Y_train, batch_size=128, epochs=EPOCHS_NUM,\n",
        "                validation_data=(X_val, Y_val), callbacks=[checkpoint, tensorboard]) \n",
        "  return CNN_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtNxcpQEe5Bk"
      },
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqPpcOUwfFyd"
      },
      "source": [
        "Reading CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkK9ZSXLeu3J"
      },
      "source": [
        "Classes = pd.read_csv('names.csv')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4enJpWpQZeh"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdVCeL8De0M6"
      },
      "source": [
        "### Train dataset created OR not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeMOhEmrezyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4311c700-ab6c-4105-e160-cd23fe26ce64"
      },
      "source": [
        "# If Train dataset created or not\n",
        "if (os.path.exists(train_image_data)):\n",
        "  train_image = np.load(train_image_data, allow_pickle=True)\n",
        "  print('Train dataset exist')\n",
        "else:\n",
        "  train_image = create_train_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Ur1Jfte952"
      },
      "source": [
        "### Test dataset created OR not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5We6426fAki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3558bb9d-88e7-4b3b-e027-857cfa96ecde"
      },
      "source": [
        "# If Test dataset created or not\n",
        "if (os.path.exists(test_image_data)):\n",
        "  test_image = np.load(test_image_data, allow_pickle=True)\n",
        "  print('Test dataset exist')\n",
        "else:\n",
        "  test_image = create_test_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qn6f-kfO5D"
      },
      "source": [
        "### Prepare X,Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPje-4zxfSbW"
      },
      "source": [
        "X = np.array([i[0] for i in train_image]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y = [i[1] for i in train_image]\n",
        "\n",
        "# One Hot Encode Y\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "# Normalization X \n",
        "X = X.astype('float32') / 255\n",
        "\n",
        "# split train and validation\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS1XfL5pQm5Y"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNezFSsge4Kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93489d78-f5d5-49e1-aff3-99b6f56a8c19"
      },
      "source": [
        "CNN_model = train_CNN_model(X_train,Y_train, X_val, Y_val, MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "77/77 [==============================] - 52s 652ms/step - loss: 3.4084 - accuracy: 0.1988 - val_loss: 37.8670 - val_accuracy: 0.1660\n",
            "Epoch 2/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 1.4883 - accuracy: 0.3213 - val_loss: 5.8086 - val_accuracy: 0.1660\n",
            "Epoch 3/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 1.1704 - accuracy: 0.5169 - val_loss: 2.2975 - val_accuracy: 0.2144\n",
            "Epoch 4/50\n",
            "77/77 [==============================] - 49s 637ms/step - loss: 1.0100 - accuracy: 0.5960 - val_loss: 2.5221 - val_accuracy: 0.3075\n",
            "Epoch 5/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.8714 - accuracy: 0.6575 - val_loss: 1.4959 - val_accuracy: 0.4873\n",
            "Epoch 6/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.7608 - accuracy: 0.7267 - val_loss: 1.8065 - val_accuracy: 0.4742\n",
            "Epoch 7/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.6672 - accuracy: 0.7687 - val_loss: 1.0229 - val_accuracy: 0.6402\n",
            "Epoch 8/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.6505 - accuracy: 0.7777 - val_loss: 0.8383 - val_accuracy: 0.7150\n",
            "Epoch 9/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.5470 - accuracy: 0.8118 - val_loss: 0.8253 - val_accuracy: 0.7241\n",
            "Epoch 10/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.5371 - accuracy: 0.8220 - val_loss: 0.7085 - val_accuracy: 0.7537\n",
            "Epoch 11/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.5030 - accuracy: 0.8339 - val_loss: 0.5440 - val_accuracy: 0.8081\n",
            "Epoch 12/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.4557 - accuracy: 0.8459 - val_loss: 0.5760 - val_accuracy: 0.8124\n",
            "Epoch 13/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.4525 - accuracy: 0.8533 - val_loss: 0.5147 - val_accuracy: 0.8304\n",
            "Epoch 14/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.4643 - accuracy: 0.8485 - val_loss: 1.2856 - val_accuracy: 0.6096\n",
            "Epoch 15/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.4242 - accuracy: 0.8565 - val_loss: 0.6462 - val_accuracy: 0.7618\n",
            "Epoch 16/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3979 - accuracy: 0.8668 - val_loss: 1.1693 - val_accuracy: 0.6336\n",
            "Epoch 17/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.3872 - accuracy: 0.8757 - val_loss: 0.4729 - val_accuracy: 0.8440\n",
            "Epoch 18/50\n",
            "77/77 [==============================] - 49s 640ms/step - loss: 0.3725 - accuracy: 0.8797 - val_loss: 0.6795 - val_accuracy: 0.7865\n",
            "Epoch 19/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3671 - accuracy: 0.8793 - val_loss: 1.2389 - val_accuracy: 0.6516\n",
            "Epoch 20/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.3436 - accuracy: 0.8845 - val_loss: 0.8993 - val_accuracy: 0.7027\n",
            "Epoch 21/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3151 - accuracy: 0.8931 - val_loss: 0.5707 - val_accuracy: 0.8190\n",
            "Epoch 22/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3212 - accuracy: 0.8915 - val_loss: 0.5023 - val_accuracy: 0.8437\n",
            "Epoch 23/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3236 - accuracy: 0.8931 - val_loss: 0.6353 - val_accuracy: 0.7820\n",
            "Epoch 24/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.3300 - accuracy: 0.8930 - val_loss: 0.4989 - val_accuracy: 0.8276\n",
            "Epoch 25/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.2999 - accuracy: 0.9004 - val_loss: 0.4936 - val_accuracy: 0.8373\n",
            "Epoch 26/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.2695 - accuracy: 0.9145 - val_loss: 0.8139 - val_accuracy: 0.7585\n",
            "Epoch 27/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.2727 - accuracy: 0.9090 - val_loss: 0.8557 - val_accuracy: 0.7381\n",
            "Epoch 28/50\n",
            "77/77 [==============================] - 49s 639ms/step - loss: 0.2678 - accuracy: 0.9086 - val_loss: 0.8486 - val_accuracy: 0.7670\n",
            "Epoch 29/50\n",
            "77/77 [==============================] - 49s 638ms/step - loss: 0.2614 - accuracy: 0.9121 - val_loss: 0.4272 - val_accuracy: 0.8635\n",
            "Epoch 30/50\n",
            "77/77 [==============================] - 49s 636ms/step - loss: 0.2535 - accuracy: 0.9159 - val_loss: 0.5578 - val_accuracy: 0.8214\n",
            "Epoch 31/50\n",
            "77/77 [==============================] - 49s 634ms/step - loss: 0.2599 - accuracy: 0.9151 - val_loss: 0.5024 - val_accuracy: 0.8416\n",
            "Epoch 32/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.2604 - accuracy: 0.9106 - val_loss: 0.3806 - val_accuracy: 0.8858\n",
            "Epoch 33/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.2347 - accuracy: 0.9198 - val_loss: 0.4051 - val_accuracy: 0.8701\n",
            "Epoch 34/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.2122 - accuracy: 0.9277 - val_loss: 0.6614 - val_accuracy: 0.8390\n",
            "Epoch 35/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.2181 - accuracy: 0.9261 - val_loss: 0.8926 - val_accuracy: 0.7526\n",
            "Epoch 36/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.2073 - accuracy: 0.9333 - val_loss: 0.7141 - val_accuracy: 0.7611\n",
            "Epoch 37/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.2260 - accuracy: 0.9259 - val_loss: 0.6956 - val_accuracy: 0.7775\n",
            "Epoch 38/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.2023 - accuracy: 0.9312 - val_loss: 0.8181 - val_accuracy: 0.7927\n",
            "Epoch 39/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.2004 - accuracy: 0.9323 - val_loss: 0.4793 - val_accuracy: 0.8575\n",
            "Epoch 40/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1770 - accuracy: 0.9394 - val_loss: 0.7411 - val_accuracy: 0.8050\n",
            "Epoch 41/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1951 - accuracy: 0.9306 - val_loss: 0.5552 - val_accuracy: 0.8354\n",
            "Epoch 42/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.1797 - accuracy: 0.9358 - val_loss: 0.7207 - val_accuracy: 0.7875\n",
            "Epoch 43/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1898 - accuracy: 0.9375 - val_loss: 0.5549 - val_accuracy: 0.8454\n",
            "Epoch 44/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1819 - accuracy: 0.9383 - val_loss: 0.5657 - val_accuracy: 0.8288\n",
            "Epoch 45/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.1477 - accuracy: 0.9462 - val_loss: 0.5446 - val_accuracy: 0.8523\n",
            "Epoch 46/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1589 - accuracy: 0.9441 - val_loss: 0.5340 - val_accuracy: 0.8485\n",
            "Epoch 47/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.1720 - accuracy: 0.9439 - val_loss: 0.4460 - val_accuracy: 0.8732\n",
            "Epoch 48/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.1468 - accuracy: 0.9497 - val_loss: 0.5836 - val_accuracy: 0.8046\n",
            "Epoch 49/50\n",
            "77/77 [==============================] - 49s 632ms/step - loss: 0.1669 - accuracy: 0.9479 - val_loss: 0.5349 - val_accuracy: 0.8433\n",
            "Epoch 50/50\n",
            "77/77 [==============================] - 49s 633ms/step - loss: 0.1400 - accuracy: 0.9526 - val_loss: 0.5108 - val_accuracy: 0.8713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arnK8ypOf7GF"
      },
      "source": [
        "## Set X_test and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYtgtJBm5nJM"
      },
      "source": [
        "'''\n",
        "print(test_image.shape)\n",
        "X_test = np.array([i[0] for i in test_image]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X_test_name = [i[1] for i in test_image]\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "prediction = CNN_model.predict(X_test)\n",
        "print(len(prediction))\n",
        "\n",
        "max_pred_id = np.argmax(prediction, axis = 1)\n",
        "print(len(max_pred_id))\n",
        "\n",
        "print(list(Classes['Image'])[max_pred_id[73]])\n",
        "plt.imshow(X_test[73,:,:], cmap='gray')\n",
        "print(X_test_name[331])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7y7kBOrc76S"
      },
      "source": [
        "## Write result CSV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6gWo4hGc4LC"
      },
      "source": [
        "'''\n",
        "X_test_name = pd.Series(X_test_name, name='Image')\n",
        "max_pred_id = pd.Series(max_pred_id, name='Label')\n",
        "result_csv = pd.concat([X_test_name, max_pred_id], axis = 1)\n",
        "result_csv.to_csv('try_submit_.88.csv', index = False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}